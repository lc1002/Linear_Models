---
title: "Boostrapping"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(p8105.datasets)

library(modelr)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


* Bootstrapping and cross validation are pretty similar. Where you get a data set and do repeatedly over and over. Bootstrapping -- intends to make inference of the parameters / CI. While Cross Validation looks at how well this model works on a different dataset.

## Stimulate a dataset 

```{r}
n_samp = 250

## constant variance data
sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

## nonconstant variance data

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```

Make a plot

```{r}
sim_df_nonconst %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point()
```

```{r}
## this gives good estimates but high standard error
sim_df_nonconst %>% 
  lm(y~x, data = .) %>% 
  broom::tidy()
```

Implement a procedure so it will gives better standard error

## Let's try to use the bootstrap for inference

```{r}
## Get different regression sample everytime you run the code.
bootstrap_sample = 
  sim_df_nonconst %>% 
  sample_frac(size = 1, replace = TRUE) %>% 
  arrange(x)

lm(y~x, data = bootstrap_sample)
```

Let's write a function..

```{r}
boot_sample = function(df){
  
  sample_frac(df, size = 1, replace = TRUE)
}
```

Now, we will make a tibble to keep track of everything. 

```{r}
boot_strap_df = 
  tibble(
    strap_number = 1:1000,
    strap_sample = rerun(1000, boot_sample(sim_df_nonconst)) ##run this boot_sample function 1000 times 
  )
```

From here ... things are kinda the same as "always"

```{r}
bootstrap_results = 
  boot_strap_df %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(y~x, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>%
  unnest(results)

bootstrap_results %>% 
  ggplot(aes(x = estimate)) +
  geom_histogram() +
  facet_grid(~term, scales = "free") 
## normally distributed plot

lm(y~x, data = sim_df_nonconst) %>% 
  broom::tidy()

## estimate coefficient would be like under repeatedly sampling, what we think the right ans is.
## mapping standard deviation to a standard error of the sample
## More accurate standard error for the slope.
bootstrap_results %>% 
  group_by(term) %>% 
  summarize(
    se = sd(estimate)
  )

```


## Use `modelr`

```{r}
sim_df_nonconst %>% 
  bootstrap(n = 1000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(y~x, data = .x)),
    results = map(models, broom::tidy)
  )
```

```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    borough = neighbourhood_group
  ) %>% 
  filter(borough != "Staten Island") %>% 
  select(price, stars, borough, room_type)
```

```{r}
nyc_airbnb %>% 
  ggplot(aes(x = stars, y = price)) + 
  geom_point()
```


```{r}
## bootstrapping sample 1000 with replacement, linear model -- price against stars for each sample

airbnb_bootstrap_results = 
  nyc_airbnb %>% 
  filter(borough == "Manhattan") %>% 
  bootstrap(n = 1000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~ lm(price ~ stars, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results)

## distribution estimate coefficient of stars
ggp_star_est = 
  airbnb_bootstrap_results %>% 
  filter(term == "stars") %>% 
  ggplot(aes(estimate)) + 
  geom_density()


ggp_scatter = 
  nyc_airbnb %>% 
  filter(borough == "Manhattan") %>% 
  ggplot(aes(x = stars, y = price)) +
  geom_point()

ggp_star_est + ggp_scatter
```




